# Simulador e Analisador de Magnetostric√ß√£o

Este projeto implementa um sistema completo para simula√ß√£o, an√°lise e classifica√ß√£o de ru√≠dos de magnetostric√ß√£o em transformadores. O sistema consiste em dois componentes principais:

1. **Gerador de Amostras**: Gera sinais sint√©ticos que simulam diferentes estados de ru√≠dos de magnetostric√ß√£o.
2. **Analisador em Tempo Real**: Interface gr√°fica para captura, processamento, visualiza√ß√£o e classifica√ß√£o de sinais de √°udio.

## √çndice

- [Requisitos](#requisitos)
- [Configura√ß√£o do Ambiente](#configura√ß√£o-do-ambiente)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Gera√ß√£o de Amostras](#gera√ß√£o-de-amostras)
- [Uso do Analisador](#uso-do-analisador)
- [Redes Neurais Utilizadas](#redes-neurais-utilizadas)
- [Fluxo de Trabalho Completo](#fluxo-de-trabalho-completo)

## Requisitos

- Python 3.8 a 3.10 (Windows ü™ü), ou superior no Linux üêß
- Bibliotecas Python (ver se√ß√£o de configura√ß√£o)
- Dispositivos de √°udio para captura/reprodu√ß√£o (para uso em tempo real)

## Configura√ß√£o do Ambiente

### Cria√ß√£o do Ambiente Virtual

```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente no Linux/Mac üêß
source venv/bin/activate

# Ativar ambiente no Windows ü™ü
venv\Scripts\activate
```

### Instala√ß√£o de Depend√™ncias

```bash
# Instalar todas as depend√™ncias necess√°rias
pip install -r requirements.txt
```

#### Instala√ß√£o no Windows
No Windows, devido √† incompatibilidade de `tensorflow` e `numpy` com o Python 3.12, execute:

```bash
pip install -r requirements-windows.txt
```

Esse arquivo cont√©m vers√µes de TensorFlow e NumPy compat√≠veis com vers√µes est√°veis do Python no Windows, que n√£o suportam as vers√µes mais recentes (3.12).

As depend√™ncias principais incluem:
- **numpy**: Processamento num√©rico
- **scipy**: Processamento de sinais (filtros, transformadas)
- **librosa**: An√°lise de √°udio e extra√ß√£o de caracter√≠sticas
- **sounddevice**: Interface para dispositivos de √°udio
- **PyQt5**: Interface gr√°fica
- **matplotlib**: Visualiza√ß√£o de dados
- **tensorflow**: Aprendizado de m√°quina para classifica√ß√£o
- **tqdm**: Barra de progresso para gera√ß√£o de amostras

## Alguns parametros extras que podem ajudar.

export XLA_FLAGS="--xla_gpu_cuda_data_dir=/usr/lib/nvidia-cuda-toolkit --xla_gpu_cuda_compiler_path=$(which nvcc)"

### desabilitar o JIT/XLA e treinar na GPU sem XLA, pode usar:

export TF_XLA_FLAGS="--tf_xla_enable_xla_devices=false"

## Desativa o uso da CPU

```
export CUDA_VISIBLE_DEVICES = -1
```

No aplicativo basta usar --no_gpu

## Estrutura do Projeto

```
simulador/
‚îú‚îÄ‚îÄ simulador.py                        # Interface gr√°fica e classificador
‚îú‚îÄ‚îÄ gerador_amostras_magnetostriccao.py # Gerador de amostras
‚îú‚îÄ‚îÄ requirements.txt                    # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ ruidos_externos/                    # Diret√≥rio para sons ambientes
‚îú‚îÄ‚îÄ impulse_responses/                  # Respostas impulsivas para efeitos de sala
‚îú‚îÄ‚îÄ eq_curvas_microfone/                # Perfis de equaliza√ß√£o de microfones
‚îî‚îÄ‚îÄ samples_realistas/                  # Amostras geradas para treino/teste
    ‚îú‚îÄ‚îÄ train/
    ‚îÇ   ‚îú‚îÄ‚îÄ 0/                          # Classe 0: Normal
    ‚îÇ   ‚îú‚îÄ‚îÄ 1/                          # Classe 1: Intermedi√°rio
    ‚îÇ   ‚îî‚îÄ‚îÄ 2/                          # Classe 2: Falha
    ‚îî‚îÄ‚îÄ test/
        ‚îú‚îÄ‚îÄ 0/                          # Classe 0: Normal
        ‚îú‚îÄ‚îÄ 1/                          # Classe 1: Intermedi√°rio
        ‚îî‚îÄ‚îÄ 2/                          # Classe 2: Falha
```

## Gera√ß√£o de Amostras

O script `gerador_amostras_magnetostriccao.py` cria amostras de √°udio sint√©ticas que simulam tr√™s estados de magnetostric√ß√£o. 

A partir da vers√£o mais recente, o processo de gera√ß√£o exibe uma **barra de progresso** no terminal, mostrando quantos arquivos de treino e teste j√° foram criados, facilitando o acompanhamento da execu√ß√£o.

- **Classe 0**: Estado normal (padr√£o harm√¥nico equilibrado)
- **Classe 1**: Estado intermedi√°rio (altera√ß√µes nas harmonicas pares)
- **Classe 2**: Estado de falha (altera√ß√µes nas harmonicas √≠mpares e maior ru√≠do)

### Como Funciona o Gerador

O gerador usa os seguintes processos para criar amostras realistas:

1. **Gera√ß√£o do Sinal Base**: Cria harm√¥nicas de 60Hz com diferentes ganhos por classe
2. **Aplica√ß√£o de Ru√≠do Real**: (Opcional) Adiciona ru√≠do ambiente de grava√ß√µes reais
3. **Convolu√ß√£o com Resposta Impulsiva**: (Opcional) Aplica caracter√≠sticas ac√∫sticas de ambientes
4. **Equaliza√ß√£o de Microfone**: (Opcional) Simula resposta em frequ√™ncia de diferentes microfones

### Como Usar o Gerador

O script `gerador_amostras_magnetostriccao.py` pode ser executado diretamente pela linha de comando e aceita diversos par√¢metros para personaliza√ß√£o:

#### Principais argumentos

- `--fatorial`           : Gera todas as combina√ß√µes poss√≠veis entre sinais e todos os ru√≠dos externos (modo fatorial)
- `--destino`            : Diret√≥rio de sa√≠da das amostras (default: ./samples_realistas)
- `--n_sinais`           : N√∫mero de sinais base por classe (no modo fatorial, default: 20)
- `--total`              : N√∫mero total de amostras (modo normal, default: 200)
- `--proporcao_treino`   : Propor√ß√£o das amostras para treino (default: 0.3)
- `--proporcao_ruido`    : Propor√ß√£o das amostras com ru√≠do externo (default: 0.3)
- `--nivel-ruido` ou `-n`: N√≠vel de amplifica√ß√£o do ru√≠do externo (default: 1.5 = +50%)

#### Exemplos de uso

**Modo normal (aleat√≥rio, com propor√ß√£o de ru√≠do):**

```bash
python gerador_amostras_magnetostriccao.py --total 100 --proporcao_ruido 0.5 --nivel-ruido 2.0 --destino ./samples_realistas
```

**Modo fatorial (todas as combina√ß√µes entre cada sinal e cada ru√≠do externo):**

```bash
python gerador_amostras_magnetostriccao.py --fatorial --n_sinais 20 --nivel-ruido 1.5 --destino ./samples_fatorial
```

#### Observa√ß√µes importantes

- **Formatos aceitos para ru√≠do externo:** `.wav` e `.mp3` (coloque os arquivos em `ruidos_externos/`)
- **Dura√ß√£o das amostras:** Quando ru√≠do externo √© utilizado, a dura√ß√£o da amostra gerada ser√° igual √† do arquivo de ru√≠do externo correspondente.
- **Amplifica√ß√£o do ru√≠do:** O par√¢metro `--nivel-ruido` multiplica o volume do ru√≠do externo (1.0 = original, 2.0 = dobro, 1.5 = +50%).
- **Sa√≠da:** O script cria pastas `train` e `test` no diret√≥rio de destino, cada uma com subpastas para as classes 0, 1 e 2.

#### Ajuda

Para ver todos os par√¢metros dispon√≠veis:

```bash
python gerador_amostras_magnetostriccao.py --help
```

### Personaliza√ß√£o da Gera√ß√£o

Para personalizar a gera√ß√£o de amostras:

1. **Ru√≠dos Externos**: Adicione arquivos de √°udio WAV em `ruidos_externos/` (crie o diret√≥rio manualmente se n√£o existir: `mkdir ruidos_externos`)
2. **Respostas Impulsivas**: Adicione IRs de ambientes em `impulse_responses/`
3. **Curvas de EQ**: Adicione perfis de equaliza√ß√£o em `eq_curvas_microfone/`

## Compatibilidade de Modelos

Os arquivos de modelo `.h5` gerados em ambiente Linux (usando o `requirements.txt` com a vers√£o atual das bibliotecas) n√£o s√£o compat√≠veis com aqueles gerados em ambiente Windows (usando `requirements-windows.txt`) na nova vers√£o. Isso ocorre devido a diferen√ßas na serializa√ß√£o do formato HDF5 e nas vers√µes do TensorFlow e do NumPy entre as plataformas. Portanto, certifique-se de treinar e utilizar o modelo na mesma plataforma e ambiente em que ele foi gerado.

## Uso do Analisador

O analisador (`simulador.py`) √© uma aplica√ß√£o gr√°fica para:
- Captura e reprodu√ß√£o de √°udio em tempo real
- Processamento e visualiza√ß√£o de caracter√≠sticas espectrais
- Classifica√ß√£o de sinais usando redes neurais treinadas

### Execu√ß√£o do Analisador

```bash
# Formato b√°sico
python simulador.py <diret√≥rio_raiz>

# Exemplo com modelo pr√©-treinado
python simulador.py ./samples_realistas --model model_CNN.h5

# O diret√≥rio_raiz deve conter subpastas:
#   train/0, train/1, train/2 (para treinamento)
#   test/0, test/1, test/2 (para teste)
```

### Funcionalidades da Interface

![Interface do Analisador (representa√ß√£o)](https://exemplo.com/interface.png)

1. **Sele√ß√£o de Dispositivos**:
   - Escolha de entrada de √°udio (microfone)
   - Escolha de sa√≠da de √°udio

2. **Controles de √Åudio**:
   - Ganho de entrada
   - Ganho de sa√≠da
   - VU-meter para visualiza√ß√£o do n√≠vel RMS

3. **Visualiza√ß√µes em Tempo Real**:
   - Espectrograma (at√© 1 kHz)
   - Bandas Mel
   - FFT

4. **Opera√ß√µes de Classifica√ß√£o**:
   - Treinamento de modelos
   - Classifica√ß√£o em tempo real
   - Classifica√ß√£o de arquivos de teste
   - Indicador visual do estado detectado

### Fluxo de Trabalho na Interface

1. **Treinar Modelo**:
   - Clique em "Treinar" para criar um novo modelo
   - Selecione a arquitetura desejada na lista
   - Aguarde o treinamento e salvamento do modelo

2. **Classifica√ß√£o em Tempo Real**:
   - Clique em "Iniciar" para come√ßar a captura
   - Observe os gr√°ficos e o status em tempo real
   - Clique em "Parar" para interromper

3. **Classifica√ß√£o de Testes**:
   - Clique em "Testar" para classificar arquivos de teste
   - Observe os resultados no console
   - A classifica√ß√£o pode ser interrompida a qualquer momento

## Redes Neurais Utilizadas

O sistema possui uma interface flex√≠vel para treino e teste de diferentes arquiteturas de redes neurais para classifica√ß√£o dos sinais de √°udio. As op√ß√µes dispon√≠veis na interface s√£o:

- **CNN** (Rede Neural Convolucional)
- **RNN** (Rede Neural Recorrente)
- **SVM** (Support Vector Machine)
- **RandomForest** (Floresta Aleat√≥ria)
- **XGBoost** (Extreme Gradient Boosting)

> **Nota:** No momento, apenas a arquitetura CNN est√° implementada e pode ser treinada diretamente pela interface. As demais (RNN, SVM, RandomForest, XGBoost) est√£o presentes para fins de compara√ß√£o futura e sele√ß√£o visual, mas ainda n√£o est√£o dispon√≠veis para treino.

### CNN (Rede Neural Convolucional)
A CNN √© a arquitetura padr√£o utilizada para classifica√ß√£o dos MFCCs extra√≠dos dos sinais de √°udio. Ela √© composta pelas seguintes camadas:

```
Entrada: MFCCs [n_mfcc=40, frames]
‚Üì
Convolu√ß√£o 2D (16 filtros 3x3, ReLU)
‚Üì
MaxPooling 2D (2x2)
‚Üì
Convolu√ß√£o 2D (32 filtros 3x3, ReLU)
‚Üì
MaxPooling 2D (2x2)
‚Üì
Flatten
‚Üì
Densa (64 neur√¥nios, ReLU)
‚Üì
Sa√≠da (3 classes, Softmax)
```

- **Entrada:** MFCCs extra√≠dos do √°udio (formato imagem 2D)
- **Conv2D/MaxPooling:** Capturam padr√µes espectrais e temporais relevantes
- **Flatten/Dense:** Realizam a classifica√ß√£o final em 3 classes

### Outras Arquiteturas Previstas

- **RNN:** Indicada para sequ√™ncias temporais, pode capturar depend√™ncias de longo prazo nos sinais.
- **SVM:** Classificador tradicional eficiente para problemas lineares e n√£o-lineares com poucos dados.
- **RandomForest:** M√©todo de ensemble baseado em √°rvores de decis√£o, robusto a ru√≠dos e sobreajuste.
- **XGBoost:** Algoritmo de boosting de √°rvores, eficiente para grandes conjuntos de dados tabulares.

Essas op√ß√µes est√£o presentes na interface para facilitar testes comparativos e futuras expans√µes do sistema.

### Caracter√≠sticas e Pr√©-processamento

- **MFCCs**: Extra√ß√£o de 40 Coeficientes Cepstrais de Frequ√™ncia Mel
- **Filtragem**: Passa-baixa at√© 1 kHz usando filtro Butterworth de 4¬™ ordem
- **Padroniza√ß√£o**: Todas as amostras s√£o normalizadas e padronizadas para o mesmo tamanho

### Vantagens da CNN para Este Problema

1. **Captura de padr√µes espectrais**: As camadas convolucionais identificam padr√µes relevantes nos espectrogramas de MFCC
2. **Robustez a varia√ß√µes temporais**: O pooling fornece certa invari√¢ncia a pequenas diferen√ßas temporais
3. **Compacidade**: A rede √© pequena o suficiente para rodar em tempo real em hardware comum
4. **Generaliza√ß√£o**: Boa capacidade de detectar padr√µes em condi√ß√µes de ru√≠do vari√°vel

### Limita√ß√µes

1. **Necessidade de dados representativos**: A qualidade da classifica√ß√£o depende da variedade do conjunto de treinamento
2. **Sensibilidade a ru√≠dos n√£o vistos**: Ru√≠dos muito diferentes dos usados no treinamento podem afetar o desempenho
3. **Falta de explicabilidade**: Como em muitas redes neurais, as decis√µes n√£o s√£o totalmente interpret√°veis
4. **Limita√ß√£o a 1 kHz**: A an√°lise √© limitada a baixas frequ√™ncias, podendo perder informa√ß√µes em frequ√™ncias mais altas

## Fluxo de Trabalho Completo

Para utilizar o sistema completo:

1. **Gerar ru√≠dos urbanos** (opcional, para enriquecer os testes):
   ```bash
   python gerar_ruidos_urbanos.py
   ```

2. **Gerar amostras sint√©ticas**:
   ```bash
   python gerador_amostras_magnetostriccao.py
   ```

3. **Opcional**: Adicionar grava√ß√µes reais √†s pastas train/test correspondentes

4. **Executar o analisador**:
   ```bash
   python simulador.py ./samples_realistas
   ```

5. **Treinar um modelo** na interface gr√°fica
   - Ao trocar o modelo na lista, os bot√µes de an√°lise e classifica√ß√£o ser√£o desativados automaticamente. √â necess√°rio treinar novamente para habilit√°-los.
   - O arquivo salvo ter√° sempre o formato `model_<nome_modelo>.h5` (ex: `model_CNN.h5`).

6. **Testar o modelo** com amostras de teste

7. **Usar em tempo real** com um microfone para monitoramento cont√≠nuo

---

## Uso de TinyML no STM32

Este projeto oferece um script para converter modelos Keras (.h5) em formatos compat√≠veis com TinyML para microcontroladores STM32 (TFLite e array C).

### Passos para Converter e Integrar

1. **Converta o modelo .h5 para TFLite e array C:**

   ```bash
   python h5_to_stm32_tinyml.py caminho/do/modelo.h5
   # Sa√≠das: modelo.tflite e modelo.h (array C)
   ```
   
   Par√¢metros opcionais:
   - `--tflite`: Caminho de sa√≠da do arquivo .tflite
   - `--c`: Caminho de sa√≠da do arquivo .h (array C)
   - `--var`: Nome da vari√°vel C (default: model_tflite)

2. **Projeto Base STM32:**
   - Um esqueleto de projeto est√° dispon√≠vel em `stm32_base/`.
   - Copie o arquivo `.h` gerado para `stm32_base/Core/Inc/model_tflite.h`.
   - Siga o guia em `stm32_base/README_STM32_PROJECT.md` para integra√ß√£o no seu projeto STM32.

3. **Integra√ß√£o no C√≥digo C:**
   - Inclua o arquivo `.h` no seu c√≥digo STM32:
     ```c
     #include "model_tflite.h"
     // Use model_tflite e model_tflite_len
     ```
   - Importe e integre a biblioteca TensorFlow Lite Micro conforme instru√ß√µes no projeto base.

### Depend√™ncias para Convers√£o
- Python 3.8+
- tensorflow
- numpy

Instale com:
```bash
pip install tensorflow numpy
```

---

Este projeto foi desenvolvido para auxiliar na detec√ß√£o e classifica√ß√£o de problemas de magnetostric√ß√£o em transformadores, fornecendo ferramentas para simula√ß√£o, treinamento, aplica√ß√£o em tempo real e agora integra√ß√£o com microcontroladores STM32 via TinyML.
